% !TEX root = ../thesis.texSecondly
%
\chapter{Conclusion}
\label{sec:conclusion}
In this thesis we present an zero-knowledge image retrieval system employing a \acrlong{fcn} for efficient object detection. With a set of transformed samples derived from a query image we fine-tune the underlying \gls{resnet}. Training is done without a training progress dependent abort condition. The linear classifier is converted to a convolution to predict sparse class probabilities on images of varying size. Using these probability maps we predict the existence of alike objects in images. We yield these patches and thereby we retrieve object instances from image set related to the training samples.

With our results on \textsc{Pascal}-Part and the application on art historical images we provide evidence that this approach can carry out image retrieval in unlabeled, context-less images using a small number of examples, ultimately only a single one. On the one hand, the tests on \textsc{Pascal}-Part verify the supposition, that providing the network with more positives image samples drastically improves its detection results, on the other hand we showed that under our test settings, results quickly converged over an increasing number of examples.
Although we prove the methods effectiveness we recognize multiple drawbacks. Firstly the time complexity \tref{sec:results:time} restricts its use on small datasets of images and makes instance retrieval somewhat cumbersome. Secondly our region scoring method throughout under-scales object boxes thus serving more as a translation prediction.
The approach could be continued and improved on multiple different ways. Of most importance is the unanswered question, how to use the image representation provided by the deep filter of a \gls{cnn} to bootstrap an approximate object detector without having to actually iteratively train the network. We could not test any approaches in this domain and as such can not predict a possible solution.\\
To fasten the approach it may be possible to formulate the complete pipeline inside the neural network, reducing time costs. Taking densities of regions is nothing else than average pooling and thus could be done within the network after convolutional upsampling.

All code is made publicly available under \url{https://github.com/mrtukkin/bachelor-thesis}.
